[
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "World Happiness Report (WHR) Analysis",
    "section": "",
    "text": "Happiness is a key measure of societal well-being, influenced by both economic (e.g., GDP per capita) and non-economic factors (e.g., social support, freedom, and governance). However, understanding how these factors interact remains a challenge.\nThis project aims to analyze the strongest predictors of happiness using data from the World Happiness Report and develop an interactive visualization tool to explore these relationships. By making happiness data more accessible and insightful, this study supports evidence-based decision-making for policymakers and researchers seeking to enhance well-being worldwide."
  },
  {
    "objectID": "proposal.html#exploratory-data-analysis-eda",
    "href": "proposal.html#exploratory-data-analysis-eda",
    "title": "World Happiness Report (WHR) Analysis",
    "section": "4.1 Exploratory Data Analysis (EDA)",
    "text": "4.1 Exploratory Data Analysis (EDA)\nEDA is the first step in understanding the structure and patterns within the World Happiness Report dataset. The primary objectives of EDA in this project include:\nDescriptive Statistics: Summarizing key variables such as Happiness Score, GDP per Capita, Social Support, and Life Expectancy to understand their distribution and central tendencies\n-   **Missing Values**\n\n    -   3 missing values in **GDP per capita, Social Support, Healthy Life Expectancy, Freedom to Make Life Choices, Generosity, Perceptions of Corruption, and Dystopia + Residual**.\n\n    -   No missing values in **Country Name and Ladder Score**\n\n-   **Summary Statistics**\n\n    -   **Ladder Score (Happiness Index)** ranges from **1.72** (least happy) to **7.74** (most happy), with an average of **5.53**.\n\n    -   **Log GDP per capita** varies from **0.00** to **2.14**, implying diverse economies.\n\n    -   **Social Support** has a strong influence, ranging from **0.00** to **1.61**.\n\n    -   **Freedom to Make Life Choices** ranges from **0.00** to **0.86**, showing variation in personal freedoms.\n\n    -   **Generosity & Perceptions of Corruption** have small values, indicating low levels of trust in many countries.\n\nUnivariate & Bivariate Visualizations:\n\nHistograms & Density Plots – Distribution of Happiness Scores\n\n\n\nknitr::include_graphics('plots/density-plots1.png')\n\n\n\n\n\n\n\n\n\nknitr::include_graphics('plots/density-plots2.png')\n\n\n\n\n\n\n\n\nKey Insights from Distributions: Ladder Score (Happiness Index):\n\nPeaks around 5-6, meaning most countries fall within this range. Left-skewed, indicating some countries have very low happiness scores. GDP per Capita & Social Support:\nFollows a normal distribution, with most values around 1.0 - 1.5 for GDP. Social support has a strong right tail, meaning some countries have very high support. Freedom to Make Life Choices & Generosity:\nFreedom has a broad distribution but peaks around 0.6 - 0.7. Generosity is skewed left, meaning most values are quite low. Perceptions of Corruption:\nHighly skewed left, showing many countries perceive corruption as a major issue.\nBoxplots – Comparison of happiness scores across regions\n\n\nhappiness_data &lt;- read_excel(file_path) %&gt;% clean_names()  # Clean column names\n\n# Generate a Boxplot for Happiness Scores across Years\nggplot(happiness_data, aes(x = as.factor(year), y = life_ladder)) + \n  geom_boxplot(fill = \"skyblue\", color = \"black\") + \n  labs(title = \"Happiness Score Distribution by Year\",\n       x = \"Year\",\n       y = \"Happiness Score (Life Ladder)\") + \n  theme_minimal()\n\n\n\n\n\n\n\n# Generate a Boxplot for GDP per Capita across Years\nggplot(happiness_data, aes(x = as.factor(year), y = log_gdp_per_capita)) + \n  geom_boxplot(fill = \"lightgreen\", color = \"black\") + \n  labs(title = \"GDP per Capita Distribution by Year\",\n       x = \"Year\",\n       y = \"Log GDP per Capita\") + \n  theme_minimal()\n\n\n\n\n\n\n\n# Generate a Boxplot for Social Support across Years\nggplot(happiness_data, aes(x = as.factor(year), y = social_support)) + \n  geom_boxplot(fill = \"lightcoral\", color = \"black\") + \n  labs(title = \"Social Support Distribution by Year\",\n       x = \"Year\",\n       y = \"Social Support\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\nCorrelation Analysis\nTo identify which factors have the strongest relationship with happiness.\no   *Measure the Strength of Relationships* – Identify which factors (GDP per capita, social support, freedom, generosity, corruption perception, etc.) have the strongest positive or negative correlation with happiness.\n\no   *Detect Key Influencers* – Determine whether economic factors (e.g., GDP per capita) or social indicators (e.g., social support, freedom) have a greater impact on happiness.\n\nknitr::include_graphics('plots/correlation-heatmap.png')\n\n\n\n\n\n\n\n\nCorrelation Insights:\nHappiness (Ladder Score) has the strongest correlations with:\n\nSocial Support (0.81) → Countries with stronger support systems are generally happier. GDP per Capita (0.77) → Wealthier countries tend to be happier. Healthy Life Expectancy (0.76) → Better health leads to higher happiness. Weak or Negative Correlations:\nGenerosity (0.13) and Perceptions of Corruption (0.45) have low influence on happiness. Dystopia + Residual (0.53) captures unexplained variance, slightly correlated.\nGeospatial Analysis:\n\nMapping happiness scores across countries to highlight global patterns\no   *Identify Global Happiness Trends* – Highlight regions with consistently high or low happiness levels, revealing geographical clusters of well-being.\n\no   *Compare Regional Differences* – Examine how happiness varies across continents and correlate findings with economic, social, and governance factors."
  },
  {
    "objectID": "proposal.html#confirmatory-data-analysis-cda",
    "href": "proposal.html#confirmatory-data-analysis-cda",
    "title": "World Happiness Report (WHR) Analysis",
    "section": "4.2 Confirmatory Data Analysis (CDA)",
    "text": "4.2 Confirmatory Data Analysis (CDA)\nRegression Analysis: Objective: Identify the strongest predictors of happiness by modeling the relationship between the dependent variable (Happiness Score/Life Ladder) and independent variables (e.g., GDP per capita, social support, freedom, corruption perception, etc.).\nMethod: Use Multiple Linear Regression (MLR) to quantify the impact of each factor on happiness scores. Perform Stepwise Regression to refine the model and select only the most significant predictors. Check for multicollinearity using Variance Inflation Factor (VIF) to ensure predictor variables are independent.\nOutcome: A predictive model that explains which factors contribute the most to national happiness.\nFeature Importance Analysis: Objective: Understand which variables influence happiness the most when applying non-linear models.\nMethod:\nTrain Random Forest Regression and compute feature importance scores. Use SHAP (SHapley Additive exPlanations) values to interpret how each feature contributes to happiness. Compare machine learning models (Random Forest, Gradient Boosting, etc.) to check if non-linear relationships exist.\nOutcome: A ranked list of happiness predictors, identifying both strong contributors and lesser influential factors.\nClustering Analysis: Objective: Group countries based on similarities in happiness determinants to uncover hidden patterns.\nMethod:\nUse K-Means Clustering to categorize countries into groups based on economic, social, and governance factors. Apply Hierarchical Clustering to visualize the relationships between similar countries. Perform PCA (Principal Component Analysis) to reduce dimensionality and highlight key differences.\nOutcome: Clusters of countries with similar happiness profiles, allowing for comparative regional analysis.\nLongitudinal Analysis: Objective: Examine how happiness scores evolve over time and assess the impact of global events (e.g., economic crises, political shifts, COVID-19 pandemic).\nMethod:\nUse Trend Analysis with LOESS Smoothing to visualize long-term patterns. Apply ARIMA (AutoRegressive Integrated Moving Average) or Exponential Smoothing to forecast future happiness trends. Conduct Interrupted Time Series Analysis (ITSA) to measure the impact of specific events on happiness scores.\nOutcome: Insights into how happiness levels have changed across different periods and predictions for future trends."
  },
  {
    "objectID": "Minutes of Meeting/meeting1.html",
    "href": "Minutes of Meeting/meeting1.html",
    "title": "ISSS608 Group 14 Meeting Minutes 1",
    "section": "",
    "text": "Project Meeting 1: Project Proposal, Project Methodology, Project Timeline\nDate: 05/03/2025\nTime: 8.00pm – 10.00pm\nIn Attendance: Andrea YEO Si Han, Dhreeti SHAH, OU Yi Ming\nMinutes Taker: Andrea YEO Si Han"
  },
  {
    "objectID": "Minutes of Meeting/meeting1.html#discussion-on-proposed-topics",
    "href": "Minutes of Meeting/meeting1.html#discussion-on-proposed-topics",
    "title": "ISSS608 Group 14 Meeting Minutes 1",
    "section": "3.1 Discussion on Proposed Topics:",
    "text": "3.1 Discussion on Proposed Topics:\n\n3.1.1 Evaluation of the financial transactions and fraud detection dataset\nDhreeti suggested analyzing financial transactions and fraud detection using a dataset available on Kaggle. She noted that this dataset is well-suited for Exploratory Data Analysis (EDA) and predictive modeling techniques such as classification and anomaly detection. The dataset included various transaction types, timestamps, and fraud indicators, making it a compelling choice for understanding financial fraud patterns.\nGood:\n\nContained diverse transaction types and timestamps.\nSuitable for predictive modeling and anomaly detection.\nCould provide insights into fraud trends and detection patterns.\n\nBad:\n\nData credibility concerns due to the confidential nature of financial transactions.\nLack of transparency in data sourcing and potential synthetic data issues.\nLimited time period (Total: 8 years), reducing the ability to analyze long-term trends.\nNarrow scope for exploratory data analysis beyond anomaly detection. There may or may not be any anomaly in the dataset.\n\n\n\n3.1.2 Evaluation of the World Happiness Report (WHR) dataset\nAndrea introduced the idea of analyzing global happiness trends using data from the World Happiness Report (WHR). The dataset includes economic, social, and governance-related factors that contribute to national well-being. This dataset spans from 2008 to 2014 and is released as an annual report. It provides an opportunity to explore how happiness levels change year over year for different countries and identify patterns over time. By examining key contributing factors such as GDP per capita, social support, life expectancy, freedom, generosity, and perceptions of corruption, this dataset allows for an in-depth analysis of what influences a country’s happiness score. It will be particularly interesting to visualize trends across different regions and observe how certain global or national events impact overall happiness.\nGood:\n\nCovers at least 16 years of data (2008-2024), enabling trend analysis.\nProvides a mix of economic, social, and governance factors, allowing for a multi-dimensional exploration of happiness.\nOpen-source and publicly available, ensuring data credibility.\nAllows for geographic and time-series visualizations.\nPotential for interactive dashboards to explore how different factors influence happiness across countries and over time.\n\nBad:\n\nSome variables may have missing values, requiring data cleaning and imputation.\nLimited number of happiness-related factors (total of 8), which may restrict deeper analysis on additional influences beyond those included.\n\n\n\n3.1.3 Evaluation of the Tourism dataset\nYi Ming suggested analyzing tourism trends using a dataset from the Singapore Department of Statistics (DOS). This dataset contains data on visitor arrivals on a month-to-month basis across countries, hotel occupancy rates, and available room nights. It is suited for seasonal forecasting, trend analysis, and geographic visualization, making it a strong candidate for exploring tourism behavior and economic impact.\nGood:\n\nProvides structured data on international visitor arrivals, hotel occupancy, and tourism trends over time.\nSuitable for seasonal trend analysis and forecasting.\nAllows for geographic and time-series visualizations.\n\nBad:\n\nPrimarily focused on tourism volume without deeper insights into traveler behavior and spending.\nExtensive existing research on tourism spending, making the analysis less original.\n\n\n\n3.1.4 Final Project Selection and Key Areas of Exploration\nAfter considering the different proposed ideas, the team narrowed the options down to two: Tourism Dataset and World Happiness Report (WHR) Dataset. Ultimately, the team unanimously decided on the World Happiness Report (WHR) Analysis due to its novelty and the opportunity to explore and apply the various data visualization techniques learned in class effectively. Using this dataset, the group aims to develop an interactive visual analytics application using Shiny that will allow users to explore happiness trends in a comprehensive and dynamic manner.\n\n\nKey Areas of Exploration:\n\nImpact of Various Factors on Happiness: Analyze how economic, social, and governance-related factors contribute to happiness across different countries and regions.\nTemporal Trends in Happiness: Examine how happiness levels have changed over time from 2008 to 2024 and identify key global events that may have influenced these changes.\nSignificant Predictors of Happiness: Determine which variables have the strongest impact on a country’s happiness score and explore regional differences in their influence."
  },
  {
    "objectID": "Minutes of Meeting/meeting1.html#proposed-methodology---broad-overall-project-approach",
    "href": "Minutes of Meeting/meeting1.html#proposed-methodology---broad-overall-project-approach",
    "title": "ISSS608 Group 14 Meeting Minutes 1",
    "section": "4.1 Proposed Methodology - Broad overall project approach",
    "text": "4.1 Proposed Methodology - Broad overall project approach\nThe team discussed the methodology for conducting the World Happiness Report Analysis, focusing on a structured approach that integrates data preparation, exploratory data analysis, confirmatory analysis, and visualization techniques.\n\n4.1.1 Data preparation\n\nImport and clean the dataset by handling missing values, normalizing data, and ensuring consistency in variable formats.\nRemove redundant or highly correlated variables to avoid overfitting in statistical analysis.\nEncode categorical variables (if needed) for analytical consistency.\nTransform time-series data to facilitate trend analysis.\n\n\n\n4.1.2 Exploratory Data Analysis (EDA) via Data Visualization Methods\nThe goal of EDA is to understand variable distributions, relationships, and trends across different regions and time periods. The team identified key visualization techniques, including:\n\nTime-series analysis:\n\nLine charts & bar plots to show how happiness scores evolve over time per country/region.\nStacked area charts to compare happiness trends across multiple countries.\n\nGeospatial visualization:\n\nChoropleth maps to display global happiness levels by country.\nHeatmaps for regional variations in specific happiness factors (e.g., social support, GDP, governance).\n\nCorrelation and distribution analysis:\n\nBubble plots & scatter plots to analyze relationships between happiness scores and key factors (e.g., GDP per capita, freedom).\nViolin & box plots to compare happiness score distributions across economic classifications.\n\n\n\n\n4.1.3 Confirmatory Data Analysis (CDA) via Statistical Methods**\nTo validate hypotheses and measure the impact of various factors on happiness, statistical methods will be applied:\n\nCorrelation analysis:\n\nPearson/Spearman correlation tests to determine the strength of relationships between happiness and key factors.\nNetwork correlation plots to visualize interdependencies among happiness variables.\n\nRegression modeling:\n\nMultiple Linear Regression (MLR) to quantify how economic, social, and governance factors predict happiness.\nFeature importance analysis using Random Forest or SHAP values to identify the most influential predictors.\n\nComparative analysis:\n\nANOVA (One-Way and Two-Way) tests to assess happiness differences across income groups, regions, or governance levels.\nT-tests & Wilcoxon tests for pairwise country comparisons of happiness scores over time.\n\n\n\n\n4.1.4 Visualization & Dashboard Development\nThe final step involves integrating Shiny to develop an interactive web-based visualization tool that:\n\nAllows users to explore happiness trends by selecting regions, time periods, and key influencing factors.\nProvides real-time filtering and comparison tools for analyzing multiple countries side-by-side.\nIntegrates predictive modeling outputs to showcase which factors most significantly affect happiness scores."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "World Happiness Visualization",
    "section": "",
    "text": "Hello, Welcome to our Final Project for Visual Analytics\nHere you will find our proposal, our shiny dashboard and other important things."
  },
  {
    "objectID": "acknowledgement.html",
    "href": "acknowledgement.html",
    "title": "Acknowledgement",
    "section": "",
    "text": "About this project\nWe would like to express our deepest gratitude to Prof. Kam for his invaluable teachings and insightful advice throughout this project. His guidance has greatly enriched our understanding and helped refined our approach, and his support has been instrumental in shaping the outcomes of this work. Huge thank for his encouragement and dedication to fostering learning and growth."
  },
  {
    "objectID": "dataprep.html",
    "href": "dataprep.html",
    "title": "World Happiness Report (WHR) Data Preparation",
    "section": "",
    "text": "pacman::p_load(tidyverse, janitor, slider)"
  },
  {
    "objectID": "dataprep.html#loading-of-required-packages",
    "href": "dataprep.html#loading-of-required-packages",
    "title": "World Happiness Report (WHR) Data Preparation",
    "section": "",
    "text": "pacman::p_load(tidyverse, janitor, slider)"
  },
  {
    "objectID": "dataprep.html#importing-of-data",
    "href": "dataprep.html#importing-of-data",
    "title": "World Happiness Report (WHR) Data Preparation",
    "section": "Importing of data",
    "text": "Importing of data\nTo combine all the different years of data in their respective csv files, there is a need to do a column mapping due to the different naming conventions used in the different years. The year was also populated using the file name which contains the year the data was obtained.\nThe following function was created to obtain the different naming convention of column headers across all the years.\n\nfolder &lt;- \"data_files/yearly_data/\"\n\nget_column_headers_by_file &lt;- function(folder_path) {\n  file_list &lt;- list.files(path = folder_path, pattern = \"*.csv\", full.names = TRUE)\n  \n  header_list &lt;- map_dfr(file_list, function(file) {\n    col_names &lt;- names(read_csv(file, n_max = 0))\n    cleaned_names &lt;- janitor::make_clean_names(col_names)\n    tibble(\n      file = basename(file),\n      column = cleaned_names\n    )\n  })\n  \n  return(header_list)\n}\n\nheaders_df &lt;- get_column_headers_by_file(folder)\n\nThe following code chunk was used to standardize the column headers naming convention and populate the year the data was collected.\n\n# Column mapping\ncolumn_mapping &lt;- list(\n  country = c(\"country_name\", \"country\", \"country_or_region\"),\n  ladder_score = c(\"ladder_score\", \"happiness_score\", \"score\"),\n  economy_score = c(\"explained_by_log_gdp_per_capita\", \"explained_by_gdp_per_capita\", \"gdp_per_capita\", \"economy_gdp_per_capita\"),\n  social_score = c(\"explained_by_social_support\", \"social_support\", \"family\"),\n  lifeexpectancy_score = c(\"explained_by_healthy_life_expectancy\", \"healthy_life_expectancy\", \"health_life_expectancy\"),\n  freedom_score = c(\"explained_by_freedom_to_make_life_choices\", \"freedom_to_make_life_choices\", \"freedom\"),\n  generosity_score = c(\"explained_by_generosity\", \"generosity\"),\n  corrperception_score = c(\"explained_by_perceptions_of_corruption\", \"perceptions_of_corruption\", \"trust_government_corruption\"),\n  residual_score = c(\"dystopia_residual\", \"dystopia_1_83_residual\", \"dystopia_residual\")\n)\n\n# Function to clean and standardize columns\nstandardize_columns &lt;- function(df) {\n  df &lt;- df %&gt;% janitor::clean_names()\n\n  for (std_name in names(column_mapping)) {\n    matched_name &lt;- column_mapping[[std_name]]\n    current_names &lt;- names(df)\n    found &lt;- intersect(matched_name %&gt;% tolower(), current_names)\n    if (length(found) &gt; 0) {\n      names(df)[which(names(df) == found[1])] &lt;- std_name\n    }\n  }\n  return(df)\n}\n\n# Function to extract year from filename\nextract_year &lt;- function(file_name) {\n  year_match &lt;- str_extract(file_name, \"\\\\d{4}\")  # Extracts 4-digit year\n  return(as.integer(year_match))\n}\n\n# Function to read and process all CSV files\ncombine_csv_files &lt;- function(folder_path) {\n  file_list &lt;- list.files(path = folder_path, pattern = \"*.csv\", full.names = TRUE)\n  combined_data &lt;- map(file_list, function(file) {\n    df &lt;- read_csv(file, col_types = cols(.default = \"c\")) %&gt;%\n      standardize_columns() %&gt;%\n      mutate(\n        source_file = basename(file),\n        year = extract_year(basename(file)) - 1\n      ) %&gt;%\n      select(any_of(c(\"year\", names(column_mapping))))\n    return(df)\n  }) %&gt;%\n    bind_rows()\n  return(combined_data)\n}\n\nfolder_path &lt;- \"data_files/yearly_data/\"\nraw_data &lt;- combine_csv_files(folder_path)\n\n# Preview\nglimpse(raw_data)\n\nRows: 1,510\nColumns: 10\n$ year                 &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2…\n$ country              &lt;chr&gt; \"Switzerland\", \"Iceland\", \"Denmark\", \"Norway\", \"C…\n$ ladder_score         &lt;chr&gt; \"7.587\", \"7.561\", \"7.527\", \"7.522\", \"7.427\", \"7.4…\n$ economy_score        &lt;chr&gt; \"1.39651\", \"1.30232\", \"1.32548\", \"1.459\", \"1.3262…\n$ social_score         &lt;chr&gt; \"1.34951\", \"1.40223\", \"1.36058\", \"1.33095\", \"1.32…\n$ lifeexpectancy_score &lt;chr&gt; \"0.94143\", \"0.94784\", \"0.87464\", \"0.88521\", \"0.90…\n$ freedom_score        &lt;chr&gt; \"0.66557\", \"0.62877\", \"0.64938\", \"0.66973\", \"0.63…\n$ generosity_score     &lt;chr&gt; \"0.29678\", \"0.4363\", \"0.34139\", \"0.34699\", \"0.458…\n$ corrperception_score &lt;chr&gt; \"0.41978\", \"0.14145\", \"0.48357\", \"0.36503\", \"0.32…\n$ residual_score       &lt;chr&gt; \"2.51738\", \"2.70201\", \"2.49204\", \"2.46531\", \"2.45…"
  },
  {
    "objectID": "dataprep.html#cleaning-of-data",
    "href": "dataprep.html#cleaning-of-data",
    "title": "World Happiness Report (WHR) Data Preparation",
    "section": "Cleaning of Data",
    "text": "Cleaning of Data\nFirst, the missing values for residual_score will be populated by calculating the residual.\n\ncleaned_data &lt;- raw_data %&gt;%\n  mutate(across(any_of(c(\"ladder_score\", \"economy_score\", \"social_score\", \"lifeexpectancy_score\", \"freedom_score\", \"generosity_score\", \"corrperception_score\", \"residual_score\")), as.numeric)) %&gt;%\n  mutate(residual_score = if_else(\n    is.na(residual_score), \n    ladder_score - economy_score - social_score - \n    lifeexpectancy_score - freedom_score - \n    generosity_score - corrperception_score, \n    residual_score\n  ))\n\nNext, the country’s rank in the respective year will be re-populated based on the ladder_score.\n\ncleaned_data &lt;- cleaned_data %&gt;%\n  group_by(year) %&gt;%\n  arrange(desc(ladder_score)) %&gt;%\n  mutate(rank = row_number()) %&gt;%\n  ungroup()\n\nBefore we map the countries to the regions, the countries name is also observed to have different naming conventions which needs to be fixed\n\n# Removal of special characters\ncleaned_data &lt;- cleaned_data %&gt;%\n  mutate(country = str_replace_all(country, \"\\\\*\", \"\") %&gt;% str_trim())\n\n\n# Country name matching\ncountry_name_fixes &lt;- c(\n  \"Czech Republic\" = \"Czechia\",\n  \"Congo (Brazzaville)\" = \"Congo\",\n  \"Congo (Kinshasa)\" = \"Congo, Democratic Republic of the\",\n  \"Congo\" = \"Congo, Democratic Republic of the\",\n  \"State of Palestine\" = \"Palestine, State of\",\n  \"Palestinian Territories\" = \"Palestine, State of\",\n  \"Hong Kong S.A.R. of China\" = \"Hong Kong\",\n  \"Hong Kong S.A.R., China\" = \"Hong Kong\",\n  \"South Korea\" = \"Korea, Democratic People's Republic of\",\n  \"Macedonia\" = \"North Macedonia\",\n  \"Russia\" = \"Russian Federation\",\n  \"Eswatini, Kingdom of\" = \"Eswatini\",\n  \"Netherlands\" = \"Netherlands, Kingdom of the\",\n  \"United Kingdom\" = \"United Kingdom of Great Britain and Northern Ireland\",\n  \"United States\" = \"United States of America\",\n  \"Venezuela\" = \"Venezuela, Bolivarian Republic of\",\n  \"Taiwan\" = \"Taiwan, Province of China\",\n  \"Taiwan Province of China\" = \"Taiwan, Province of China\",\n  \"Trinidad & Tobago\" = \"Trinidad and Tobago\",\n  \"Vietnam\" = \"Viet Nam\",\n  \"Moldova\" = \"Moldova, Republic of\",\n  \"Bolivia\" = \"Bolivia, Plurinational State of\",\n  \"Northern Cyprus\" = \"Cyprus\",\n  \"North Cyprus\" = \"Cyprus\",\n  \"Turkey\" = \"Türkiye\",\n  \"Turkiye\" = \"Türkiye\",\n  \"Ivory Coast\" = \"Côte d'Ivoire\",\n  \"Laos\" = \"Lao People's Democratic Republic\",\n  \"Iran\" = \"Iran, Islamic Republic of\",\n  \"Swaziland\" = \"Eswatini\",\n  \"Tanzania\" = \"Tanzania, United Republic of\",\n  \"Syria\" = \"Syrian Arab Republic\"\n)\n\n# Apply mapping\ncleaned_data &lt;- cleaned_data %&gt;%\n  mutate(country_recode = recode(country, !!!country_name_fixes))\n\nCountry-region mapping will be also be implemented for future geographical analysis. The mapping will be obtained from a github url.\n\nurl &lt;- \"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\"\n\n# Read the CSV file into a DataFrame\ncountry_region_mapping &lt;- read_csv(url)\n\n# Map the cleaned country names to its region\ncleaned_data &lt;- cleaned_data %&gt;%\n  left_join(country_region_mapping %&gt;% select(name, region), by = c(\"country_recode\" = \"name\")) %&gt;%\n  mutate(region = if_else(is.na(region), \"Unknown\", region))\n\nThe country column is then recoded with the country_recoded column with Cyprus mapped back to either Northern Cyrpus and North Cyprus in the years 2014-2021 accordingly with the country being combined to Cyprus in 2022-2023 as per the original dataset.\n\ncyprus_variant &lt;- cleaned_data %&gt;%\n  filter(country %in% c(\"North Cyprus\", \"Northern Cyprus\")) %&gt;%\n  distinct(year, country) %&gt;%\n  mutate(\n    flipped_variant = case_when(\n      country == \"North Cyprus\" ~ \"Northern Cyprus\",\n      country == \"Northern Cyprus\" ~ \"North Cyprus\"\n    )\n  )%&gt;%\n  select (year, flipped_variant)\n\ncleaned_data &lt;- cleaned_data %&gt;%\n  left_join(cyprus_variant, by = \"year\") %&gt;%\n  mutate(\n    country = if_else(country == \"Cyprus\" & !is.na(flipped_variant),\n                      flipped_variant,\n                      country)\n  ) %&gt;%\n  select(-flipped_variant)\n\ncleaned_data &lt;- cleaned_data %&gt;%\n  mutate(country = if_else(\n    country %in% c(\"Cyprus\", \"Northern Cyprus\", \"North Cyprus\"),\n    country,            # keep the original\n    country_recode      # use the recoded version\n  )) %&gt;%\n  select(-country_recode)\n\nAfter all the preliminary cleaning of dataset is performed, a summary of the cleaned_data is shown below.\n\nsummary(cleaned_data)\n\n      year        country           ladder_score   economy_score   \n Min.   :2014   Length:1510        Min.   :1.721   Min.   :0.0000  \n 1st Qu.:2016   Class :character   1st Qu.:4.604   1st Qu.:0.7407  \n Median :2018   Mode  :character   Median :5.472   Median :1.0706  \n Mean   :2018                      Mean   :5.449   Mean   :1.0528  \n 3rd Qu.:2021                      3rd Qu.:6.269   3rd Qu.:1.3740  \n Max.   :2023                      Max.   :7.842   Max.   :2.2090  \n                                                   NA's   :3       \n  social_score    lifeexpectancy_score freedom_score    generosity_score\n Min.   :0.0000   Min.   :0.0000       Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.8412   1st Qu.:0.4015       1st Qu.:0.3671   1st Qu.:0.1120  \n Median :1.0930   Median :0.6023       Median :0.4820   Median :0.1770  \n Mean   :1.0536   Mean   :0.5782       Mean   :0.4666   Mean   :0.1916  \n 3rd Qu.:1.3180   3rd Qu.:0.7608       3rd Qu.:0.5853   3rd Qu.:0.2480  \n Max.   :1.6440   Max.   :1.1410       Max.   :0.8630   Max.   :0.8381  \n NA's   :3        NA's   :4            NA's   :3        NA's   :3       \n corrperception_score residual_score        rank           region         \n Min.   :0.00000      Min.   :-0.110   Min.   :  1.00   Length:1510       \n 1st Qu.:0.05800      1st Qu.: 1.625   1st Qu.: 38.00   Class :character  \n Median :0.09989      Median : 1.974   Median : 76.00   Mode  :character  \n Mean   :0.13431      Mean   : 1.972   Mean   : 76.15                     \n 3rd Qu.:0.17176      3rd Qu.: 2.351   3rd Qu.:114.00                     \n Max.   :0.58700      Max.   : 3.838   Max.   :158.00                     \n NA's   :4            NA's   :5                                           \n\n\nThere are missing numerical evaluation scores in the dataset as shown below.\n\n# Count total missing values in each column\nmissing_summary &lt;- cleaned_data %&gt;%\n  summarise(across(everything(), ~ sum(is.na(.)))) %&gt;%\n  pivot_longer(everything(), names_to = \"column\", values_to = \"missing_count\") %&gt;%\n  arrange(desc(missing_count))\n\nprint(missing_summary)\n\n# A tibble: 12 × 2\n   column               missing_count\n   &lt;chr&gt;                        &lt;int&gt;\n 1 residual_score                   5\n 2 lifeexpectancy_score             4\n 3 corrperception_score             4\n 4 economy_score                    3\n 5 social_score                     3\n 6 freedom_score                    3\n 7 generosity_score                 3\n 8 year                             0\n 9 country                          0\n10 ladder_score                     0\n11 rank                             0\n12 region                           0\n\n\nFor each country with missing values in a given year, the missing scores are filled using the mean from the past 3 years for the same country and same column while the residual score is populated as the residual of the ladder score after deducting all the explanatory scores.\n\ncolumns_to_impute &lt;- c(\"generosity_score\", \"freedom_score\", \"social_score\", \"economy_score\", \"corrperception_score\", \"lifeexpectancy_score\")\n\ncleaned_data &lt;- cleaned_data %&gt;%\n  arrange(country, year) %&gt;%\n  group_by(country) %&gt;%\n  mutate(across(\n    all_of(columns_to_impute), \n          ~ if_else(is.na(.),\n                    slide_dbl(.x, mean, .before = 3, .complete = TRUE, na.rm = TRUE),\n                    .)\n  )) %&gt;%\n  ungroup() %&gt;%\n  mutate(residual_score = if_else(\n    is.na(residual_score), \n    ladder_score - economy_score - social_score - \n    lifeexpectancy_score - freedom_score - \n    generosity_score - corrperception_score, \n    residual_score\n  ))\n\nThere is a need to check if there are any countries with more than 10 rows of data given that the number of yearly data obtained is 10.\n\n# Check for duplicate rows\ncleaned_data %&gt;%\n  count(country) %&gt;%\n  filter(n &gt; 10)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: country &lt;chr&gt;, n &lt;int&gt;\n\n\nEach country should only have one row of data per year as confirmed below.\n\ncleaned_data %&gt;%\n  group_by(country, year) %&gt;%\n  filter(n() &gt; 1)\n\n# A tibble: 0 × 12\n# Groups:   country, year [0]\n# ℹ 12 variables: year &lt;dbl&gt;, country &lt;chr&gt;, ladder_score &lt;dbl&gt;,\n#   economy_score &lt;dbl&gt;, social_score &lt;dbl&gt;, lifeexpectancy_score &lt;dbl&gt;,\n#   freedom_score &lt;dbl&gt;, generosity_score &lt;dbl&gt;, corrperception_score &lt;dbl&gt;,\n#   residual_score &lt;dbl&gt;, rank &lt;int&gt;, region &lt;chr&gt;\n\n\nThe column types are also enforced as below.\n\ncleaned_data &lt;- cleaned_data %&gt;%\n  mutate(\n    year = as.integer(year),\n    rank = as.integer(rank),\n    country = as.character(country),\n    region = as.factor(region)\n  )"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Minutes of Meeting/minutes_of_meeting.html",
    "href": "Minutes of Meeting/minutes_of_meeting.html",
    "title": "ISSS608 Group 14 Project Meeting Minutes Records",
    "section": "",
    "text": "Project Meeting 1: Project Proposal, Project Methodology, Project Timeline\nDate: 05/03/2024\nTime: 8.00pm – 10.00pm\nIn Attendance: Andrea YEO Si Han, Dhreeti SHAH, OU Yi Ming\nClick here to view meeting minutes - 1."
  }
]